
import torch
from torch import nn
from torch import optim

from torch.utils.data import Dataset, DataLoader

from vae.model import *

import numpy as np

import os
import sys
import random

from vae.hyperparameters import *

class SpectrogramDataset(Dataset):
    def __init__(self, data, labels):
        self.win_size = 1 if len(data.shape) == 2 else data.shape[1]
        self.n_dim = data.shape[-1]
        self.n_classes = np.max(labels)

        self.data = torch.Tensor(data)
        self.labels = labels

    def __getitem__(self, idx):
        return self.data[idx], self.labels[idx]
    
    def __len__(self):
        return self.data.shape[0]

def load_data(path, win_size=3):
    print('Loading numpy data from', path)
    data = np.load(path)

    data = np.transpose(data)
    
    if win_size == 1:
        # Just use transposed data
        return data

    return np.array([data[t:t+win_size]
            for t in range(data.shape[1]-win_size+1)])

def build_dataset(path, win_size=3, batch_size=32, provide_test=True):
    """ Builds a dataset using all of the spectrograms paths in a directory
    """
    print('Building dataset using data in', path)

    phonemes = list(sorted(os.listdir(path)))
    assert '_' in phonemes, 'Datapoints for silence are required'
    del phonemes[phonemes.index('_')]
    phonemes = ['_'] + phonemes

    datum = []
    labels = []

    for i, p in enumerate(phonemes):
        dr = os.path.join(path, p)
        for f in os.listdir(dr):
            if f[-4:] != '.npy': continue

            fname = os.path.join(dr, f)
            
            data = load_data(fname, win_size=win_size)

            datum.append(data)
            labels += [i] * data.shape[0]
    
    assert len(datum) > 0, 'At least one datapoint must be available'

    data = np.concatenate(datum, axis=0)
    labels = np.array(labels)

    print('Found', len(labels), 'datapoints across', len(datum), 'files')
    print('Range:', np.min(data), np.max(data))

    # Normalize
    print('Dataset shape before normalization:', data.shape)
    mean = data.mean(axis=0)
    std = data.std(axis=0)
    data = (data - mean) / std
    print('Dataset shape after normalization:', data.shape)
    
    """
    lo = np.min(data)
    for i in range(len(data)):
        if labels[i] == 0:
            data[i] = lo * np.ones_like(data[i])
    """

    idxs = list(range(len(labels)))
    random.shuffle(idxs)
    
    if provide_test:
        i_test = idxs[:len(idxs)//8]
        i_train = idxs[len(idxs)//8:]
    else:
        i_train = idxs

    dataset_train = SpectrogramDataset(data[i_train], labels[i_train])
    dataloader_train = DataLoader(dataset_train, shuffle=True, batch_size=batch_size)

    if not provide_test:
        dataloader_test = None
    else:
        dataset_test = SpectrogramDataset(data[i_test], labels[i_test])
        dataloader_test = DataLoader(dataset_test, shuffle=True, batch_size=batch_size)

    dataloader = (dataloader_train, dataloader_test)
    
    return dataloader, phonemes

def training_round(model, opt, dataloader):
    loss = 0
    for data, labels in dataloader:
        loss += model.training_step(data, labels, opt)

    return loss / len(dataloader.dataset)

def test_round(model, dataloader):
    loss = 0
    for data, labels in dataloader:
        loss += model.training_loss(data, labels, train=False).cpu().item()

    return loss / len(dataloader.dataset)

def run_pipeline(
        data_path='./phoneme-data/spectrograms/',
        win_size=1):
    """ Constructs a model for generating speech patterns for
    given phonemes.

    data_path
            The root directory of the spectrograms generated by
            generate_spectrograms.py
    win_size
            The number of frames of spectrogram data to use in
            training samples.
    """

    # Construct data handlers
    dataloader, phonemes = build_dataset(data_path, win_size=win_size, provide_test=False)
    dataloader_train, dataloader_test = dataloader
    
    # Extract useful constants
    dataset = dataloader_train.dataset
    n_dim = dataset.n_dim

    # Construct a model
    model = Model(
            n_dim=n_dim,
            win_size=win_size,
            phonemes=phonemes).to(device)

    optimizer = optim.Adam(model.parameters(), lr=1e-3)
    
    for ep in range(1, N_EPOCHS+1):
        loss = training_round(model, optimizer, dataloader_train)
        print(f'Epoch {ep} training loss: {loss:.4f}')
        if dataloader_test is not None:
            loss = test_round(model, dataloader_test)
            print(f'Epoch {ep} test loss: {loss:.4f}')

    return model

def train(win_size=WIN_SIZE, scale=SCALE):
    model = run_pipeline(win_size=win_size*scale)

    print('Saving model to ./model.pt')
    torch.save(model, './model.pt')
    
